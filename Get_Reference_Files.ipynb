{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {\n",
    "  \"Authorization\": \"YOUR KEY\",\n",
    "  \"Accept\": \"application/vnd.api+json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_urls = []\n",
    "resetlink = 0\n",
    "current_datetime = '2019-07-10T09:00:00Z'\n",
    "link = \"https://api.developer.battlerite.com/shards/global/matches\"\n",
    "current_datetime_clean = datetime.datetime.strptime(current_datetime, '%Y-%m-%dT%H:%M:%SZ')\n",
    "starting_day = current_datetime_clean.strftime('%d')\n",
    "starting_month = current_datetime_clean.strftime('%b')\n",
    "starting_month_full = current_datetime_clean.strftime('%B')\n",
    "starting_year = current_datetime_clean.strftime('%Y')\n",
    "\n",
    "#Battlerite Asset files for current patch (Need to re-run on new asset files for new patch on whenever\n",
    "#patch version changes when gathering data) located at\n",
    "#https://github.com/StunlockStudios/battlerite-assets/tree/master/mappings\n",
    "\n",
    "gameplay_json = json.loads(requests.get('https://raw.githubusercontent.com/StunlockStudios/battlerite-assets/master/mappings/67104/gameplay.json').text)\n",
    "\n",
    "vanity_json = json.loads(requests.get('https://raw.githubusercontent.com/StunlockStudios/battlerite-assets/master/mappings/67104/AccountVanity.json').text)\n",
    "#English.txt is the same as English.ini except in .txt extension\n",
    "\n",
    "with open(os.path.join('Reference Files','English.txt')) as f:\n",
    "    content = f.readlines()\n",
    "content = [x.strip() for x in content] \n",
    "\n",
    "#Create df of conversion from Lookup ID to the actual value\n",
    "codes = []\n",
    "names = []\n",
    "for line in content:\n",
    "    code_names = line.split('=')\n",
    "    codes.append(code_names[0].upper())\n",
    "    names.append(code_names[1].upper())\n",
    "    \n",
    "CodeDf = pd.DataFrame(list(zip(codes, names)), columns = ['Code', 'Value'])\n",
    "\n",
    "'''Create Map ID Crosswalk to convert to english name'''\n",
    "\n",
    "final_mapid = []\n",
    "final_mapid2 = []\n",
    "\n",
    "\n",
    "for query_number in range(100000):\n",
    "\n",
    "    uselink = \"{}\".format(link)\n",
    "\n",
    "    query = {\n",
    "      \"sort\": \"createdAt\",\n",
    "      \"filter[createdAt-start]\": \"{}\".format(current_datetime),\n",
    "      \"page[limit]\": \"5\"}\n",
    "\n",
    "    if query_number > 0:\n",
    "\n",
    "        difference_runtime = end_runtime - start_runtime\n",
    "\n",
    "        if difference_runtime.total_seconds() < 6:\n",
    "\n",
    "            #If re-running script, make sure only sleep if positive\n",
    "            if difference_runtime.total_seconds() > 0:\n",
    "\n",
    "                #Sleep to not hit API limit per hour. Added 0.01 for rounding errors\n",
    "                time_to_sleep = 6-difference_runtime.total_seconds() + 0.01\n",
    "                time.sleep(time_to_sleep)\n",
    "\n",
    "    start_runtime = datetime.datetime.now()\n",
    "\n",
    "    #Stop Script from failing because of connection errors\n",
    "    try:\n",
    "\n",
    "        re = requests.get(uselink, headers=header, params=query)\n",
    "        re.close()\n",
    "\n",
    "    except:\n",
    "\n",
    "        print('ERROR')\n",
    "        time.sleep(600)\n",
    "        re = requests.get(uselink, headers=header, params=query)\n",
    "        re.close()\n",
    "\n",
    "    json_data = re.json()\n",
    "\n",
    "    data = json_data['data']\n",
    "    included = json_data['included']\n",
    "\n",
    "    #Get link for the next page on query\n",
    "    link = json_data['links']['next']\n",
    "    resetlink += 1\n",
    "\n",
    "    urls = []\n",
    "\n",
    "    #Get urls from list of dictionaries (not every dictionary has url, no structure)\n",
    "\n",
    "    for i in range(len(included)):\n",
    "\n",
    "        try: \n",
    "\n",
    "            urls.append(included[i]['attributes']['URL'])\n",
    "\n",
    "        except:\n",
    "\n",
    "            continue\n",
    "\n",
    "\n",
    "   #Get Map ID and game ID\n",
    "\n",
    "    mapID = []\n",
    "    gameID = []\n",
    "    mapID2 = []\n",
    "    match_gameID = []\n",
    "\n",
    "    for game in range(len(data)):\n",
    "\n",
    "        GameType = data[game]['attributes']['stats']['game']\n",
    "\n",
    "        if GameType == 'Royale':\n",
    "\n",
    "            continue\n",
    "\n",
    "        mapID.append(data[game]['attributes']['stats']['mapID'])\n",
    "        gameID.append(data[game]['id'])\n",
    "\n",
    "    gamesDf = pd.DataFrame(list(zip(mapID, gameID)),\n",
    "                          columns = ['mapID', 'gameID'])\n",
    "\n",
    "    #Get game specific information using each url(game)\n",
    "\n",
    "    for o in range(5):\n",
    "\n",
    "        url = urls[o]\n",
    "\n",
    "        #Skip game if already have data\n",
    "        if url in overall_urls:\n",
    "\n",
    "            continue\n",
    "\n",
    "        overall_urls.append(url)\n",
    "\n",
    "        r2 = requests.get(url)\n",
    "        rounds = r2.json()\n",
    "        round_info_found = False\n",
    "\n",
    "        #Find out where match data is\n",
    "        for k in range(len(rounds)):\n",
    "\n",
    "            if rounds[k]['type'] == 'com.stunlock.battlerite.match.avro.MatchResultEvent':\n",
    "\n",
    "                round_info = rounds[k]\n",
    "                round_info_found = True\n",
    "                break\n",
    "\n",
    "        #Skip game if telemetry data does not have this data structure above\n",
    "        if not round_info_found:\n",
    "            continue\n",
    "\n",
    "        #Skip if number of players is uneven\n",
    "        if (len(round_info['dataObject']['players']) % 2) != 0:\n",
    "            continue\n",
    "\n",
    "        #Try/except because variables are named differently\n",
    "        try:\n",
    "\n",
    "            #Skip if royale game\n",
    "            if round_info['dataObject']['serverType'][:5] == 'ROYAL':\n",
    "\n",
    "                continue\n",
    "\n",
    "        except:\n",
    "\n",
    "                #Skip if royale game\n",
    "            if round_info['dataObject']['match_type'][:5] == 'ROYAL':\n",
    "\n",
    "                continue\n",
    "\n",
    "        match_gameID.append(round_info['dataObject']['match_id'])\n",
    "        mapID2.append(round_info['dataObject']['map_id'])\n",
    "\n",
    "    Game_MapDf = pd.DataFrame(list(zip(match_gameID, mapID2)), columns = ['gameID', 'mapID2'])\n",
    "    Game_MapDf = pd.merge(Game_MapDf, gamesDf, on = 'gameID', how = 'inner')\n",
    "\n",
    "    for index, row in Game_MapDf.iterrows():\n",
    "        if row['mapID'] not in final_mapid:\n",
    "            final_mapid.append(row['mapID'])\n",
    "            final_mapid2.append(row['mapID2'])\n",
    "      \n",
    "    #There are only 18 different maps as of current\n",
    "    if len(final_mapid) == 18:\n",
    "        break\n",
    "\n",
    "    end_runtime = datetime.datetime.now()\n",
    "\n",
    "#Create df of Conversion of Map ID to Lookup Map ID\n",
    "MapDf = pd.DataFrame(list(zip(final_mapid, final_mapid2)), columns = ['Map ID', 'Lookup Map ID'])\n",
    "\n",
    "#Create df of conversion from Lookup Map ID to Lookup Map ID 2\n",
    "\n",
    "lookupID = []\n",
    "lookupID2 = []\n",
    "\n",
    "map_list = gameplay_json['maps']\n",
    "\n",
    "for i in range(len(map_list)):\n",
    "    lookupID.append(map_list[i]['assetID'].upper())\n",
    "    lookupID2.append(map_list[i]['name'].upper())\n",
    "    \n",
    "lookupdf = pd.DataFrame(list(zip(lookupID, lookupID2)), columns = ['Lookup Map ID', 'Lookup Map ID2'])\n",
    "lookupdf = pd.merge(MapDf, lookupdf, how = 'inner', on = 'Lookup Map ID')\n",
    "\n",
    "#Create final crosswalk of Map ID to actual map name\n",
    "FinalMaps = pd.merge(lookupdf, CodeDf, how = 'left', left_on = 'Lookup Map ID2', right_on = 'Code')\n",
    "\n",
    "FinalMaps.to_csv(os.path.join('Reference Files', 'MapID_Crosswalk_Full.csv'), index = False)\n",
    "\n",
    "#Only need MapID and name for practical purposes\n",
    "FinalMaps = FinalMaps.drop(['Lookup Map ID', 'Lookup Map ID2', 'Code'], axis = 1)\n",
    "\n",
    "FinalMaps.to_csv(os.path.join('Reference Files', 'MapID_Crosswalk.csv'), index = False)\n",
    "\n",
    "'''Get Champion Crosswalk'''\n",
    "\n",
    "champid = []\n",
    "lookupid = []\n",
    "role = []\n",
    "icon = []\n",
    "\n",
    "champions = gameplay_json['characters']\n",
    "\n",
    "for i in range(len(champions)):\n",
    "    champid.append(champions[i]['typeID'])\n",
    "    lookupid.append(champions[i]['name'].upper())\n",
    "    role.append(champions[i]['archetype'].upper())\n",
    "    icon.append(champions[i]['icon'])\n",
    "    \n",
    "ChampDf = pd.DataFrame(list(zip(champid, lookupid, role, icon)), \n",
    "                       columns = ['Champion ID', 'Champion Lookup ID', 'Role', 'Icon File Name'])\n",
    "\n",
    "FinalChamps = pd.merge(ChampDf, CodeDf, how = 'left', left_on = 'Champion Lookup ID', right_on = 'Code')\n",
    "FinalChamps.to_csv(os.path.join('Reference Files','Champion_Crosswalk_Full.csv'), index = False)\n",
    "\n",
    "FinalChamps = FinalChamps.drop(['Champion Lookup ID', 'Code'], axis = 1)\n",
    "FinalChamps.to_csv(os.path.join('Reference Files','Champion_Crosswalk.csv'), index = False)\n",
    "    \n",
    "'''Get Title crosswalk'''\n",
    "\n",
    "titleid = []\n",
    "value = []\n",
    "\n",
    "titles = vanity_json['Titles']\n",
    "\n",
    "for i in range(len(titles)):\n",
    "    titleid.append(titles[i]['StackableID'])\n",
    "    value.append(titles[i]['Text'])\n",
    "    \n",
    "TitleDf = pd.DataFrame(list(zip(titleid, value)), columns = ['Title ID', 'Value'])\n",
    "TitleDf.to_csv(os.path.join('Reference Files', 'Title_Crosswalk.csv'), index = False)\n",
    "\n",
    "'''Get Avatar Crosswalk'''\n",
    "#imageID will be the file name of the image located at:\n",
    "#https://github.com/StunlockStudios/battlerite-assets/tree/master/mappings/assets\n",
    "\n",
    "avatarid = []\n",
    "value = []\n",
    "imageid = []\n",
    "\n",
    "avatars = vanity_json['Pictures']\n",
    "\n",
    "for i in range(len(avatars)):\n",
    "    avatarid.append(avatars[i]['StackableID'])\n",
    "    value.append(avatars[i]['File'])\n",
    "    imageid.append(avatars[i]['Hash'])\n",
    "    \n",
    "AvatarDf = pd.DataFrame(list(zip(avatarid, value, imageid)), columns = ['Avatar ID', 'Value', 'Avatar File Name'])\n",
    "AvatarDf.to_csv(os.path.join('Reference Files', 'Avatar_Crosswalk.csv'), index = False)\n",
    "\n",
    "'''Get Outfit Crosswalk'''\n",
    "\n",
    "outfitid = []\n",
    "lookupid = []\n",
    "rarity = []\n",
    "\n",
    "outfits = gameplay_json['outfits']\n",
    "\n",
    "for i in range(len(outfits)):\n",
    "    outfitid.append(outfits[i]['typeID'])\n",
    "    lookupid.append(outfits[i]['name'].upper())\n",
    "    rarity.append(outfits[i]['dropRarity'])\n",
    "    \n",
    "OutfitDf = pd.DataFrame(list(zip(outfitid, lookupid, rarity)), columns = ['Outfit ID', 'Outfit Lookup ID', 'Rarity'])\n",
    "\n",
    "FinalOutfit = pd.merge(OutfitDf, CodeDf, how = 'left', left_on = 'Outfit Lookup ID', right_on = 'Code')\n",
    "\n",
    "FinalOutfit.to_csv(os.path.join('Reference Files', 'Outfit_Crosswalk_Full.csv'), index = False)\n",
    "\n",
    "FinalOutfit = FinalOutfit.drop(['Outfit Lookup ID', 'Code'], axis = 1)\n",
    "FinalOutfit.to_csv(os.path.join('Reference Files', 'Outfit_Crosswalk.csv'), index = False)\n",
    "\n",
    "'''Get Attachment Crosswalk'''\n",
    "\n",
    "attachmentid = []\n",
    "lookupid = []\n",
    "rarity = []\n",
    "\n",
    "attachments = gameplay_json['attachments']\n",
    "\n",
    "for i in range(len(attachments)):\n",
    "    attachmentid.append(attachments[i]['typeID'])\n",
    "    lookupid.append(attachments[i]['name'].upper())\n",
    "    rarity.append(attachments[i]['dropRarity'])\n",
    "    \n",
    "AttachmentDf = pd.DataFrame(list(zip(attachmentid, lookupid, rarity)), columns = ['Attachment ID', 'Attachment Lookup ID', 'Rarity'])\n",
    "\n",
    "FinalAttachment = pd.merge(AttachmentDf, CodeDf, how = 'left', left_on = 'Attachment Lookup ID', right_on = 'Code')\n",
    "FinalAttachment.to_csv(os.path.join('Reference Files', 'Attachment_Crosswalk_Full.csv'), index = False)\n",
    "\n",
    "FinalAttachment = FinalAttachment.drop(['Attachment Lookup ID', 'Code'], axis = 1)\n",
    "FinalAttachment.to_csv(os.path.join('Reference Files', 'Attachment_Crosswalk.csv'), index = False)\n",
    "\n",
    "'''Get Pose Crosswalk'''\n",
    "\n",
    "poseid = []\n",
    "lookupid = []\n",
    "rarity = []\n",
    "\n",
    "poses = gameplay_json['victoryPoses']\n",
    "\n",
    "for i in range(len(poses)):\n",
    "    poseid.append(poses[i]['typeID'])\n",
    "    lookupid.append(poses[i]['name'].upper())\n",
    "    rarity.append(poses[i]['dropRarity'])\n",
    "    \n",
    "PoseDf = pd.DataFrame(list(zip(poseid, lookupid, rarity)), columns = ['Pose ID', 'Pose Lookup ID', 'Rarity'])\n",
    "\n",
    "FinalPose = pd.merge(PoseDf, CodeDf, how = 'left', left_on = 'Pose Lookup ID', right_on = 'Code')\n",
    "FinalPose.to_csv(os.path.join('Reference Files', 'Pose_Crosswalk_Full.csv'), index = False)\n",
    "\n",
    "FinalPose = FinalPose.drop(['Pose Lookup ID', 'Code'], axis = 1)\n",
    "FinalPose.to_csv(os.path.join('Reference Files', 'Pose_Crosswalk.csv'), index = False)\n",
    "\n",
    "'''Get Mount Crosswalk'''\n",
    "\n",
    "mountid = []\n",
    "lookupid = []\n",
    "rarity = []\n",
    "\n",
    "mounts = gameplay_json['mounts']\n",
    "\n",
    "for i in range(len(mounts)):\n",
    "    mountid.append(mounts[i]['typeID'])\n",
    "    lookupid.append(mounts[i]['name'].upper())\n",
    "    rarity.append(mounts[i]['dropRarity'])\n",
    "    \n",
    "MountDf = pd.DataFrame(list(zip(mountid, lookupid, rarity)), columns = ['Mount ID', 'Mount Lookup ID', 'Rarity'])\n",
    "\n",
    "FinalMount = pd.merge(MountDf, CodeDf, how = 'left', left_on = 'Mount Lookup ID', right_on = 'Code')\n",
    "FinalMount.to_csv(os.path.join('Reference Files', 'Mount_Crosswalk_Full.csv'), index = False)\n",
    "\n",
    "FinalMount = FinalMount.drop(['Mount Lookup ID', 'Code'], axis = 1)\n",
    "FinalMount.to_csv(os.path.join('Reference Files', 'Mount_Crosswalk.csv'), index = False)\n",
    "\n",
    "'''Get Battlerites Crosswalk'''\n",
    "\n",
    "champid = []\n",
    "battleriteid = []\n",
    "lookupid = []\n",
    "battleritetype = []\n",
    "\n",
    "champs = gameplay_json['characters']\n",
    "\n",
    "for i in range(len(champs)):\n",
    "    \n",
    "    battlerites = champs[i]['battlerites']\n",
    "    \n",
    "    for j in range(len(battlerites)):\n",
    "        \n",
    "        champid.append(champs[i]['typeID'])\n",
    "        battleriteid.append(battlerites[j]['typeID'])\n",
    "        lookupid.append(battlerites[j]['name'].upper())\n",
    "        battleritetype.append(battlerites[j]['type'])\n",
    "        \n",
    "BattleriteDf = pd.DataFrame(list(zip(champid, battleriteid, lookupid, battleritetype)),\n",
    "                           columns = ['Champion ID', 'Battlerite ID', 'Battlerite Lookup ID', 'Battlerite Type'])\n",
    "\n",
    "FinalBattlerite = pd.merge(BattleriteDf, CodeDf, how = 'left', left_on = 'Battlerite Lookup ID', right_on = 'Code')\n",
    "FinalBattlerite.to_csv(os.path.join('Reference Files', 'Battlerite_Crosswalk_Full.csv'), index = False)\n",
    "\n",
    "FinalBattlerite = FinalBattlerite.drop(['Champion ID', 'Battlerite Lookup ID', 'Code'], axis = 1)\n",
    "FinalBattlerite.to_csv(os.path.join('Reference Files', 'Battlerite_Crosswalk.csv'), index = False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
